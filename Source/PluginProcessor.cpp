/*
==============================================================================

This file was auto-generated by the Jucer!

It contains the basic startup code for a Juce application.

==============================================================================
*/

#include "PluginProcessor.h"
#include "PluginEditor.h"

AudioProcessor* JUCE_CALLTYPE createPluginFilter();

const float defaultBypass = 0.0f;
const float defaultGain = 1.0f;
const float defaultDelay = 0.0f;
const float defaultDelayTime = 0.01f;
const float defaultPan = 0.5f;
const float defaultMidSide = 0.5f;

//==============================================================================
JuceDemoPluginAudioProcessor::JuceDemoPluginAudioProcessor()
	: delayBuffer (2, 12000)
{
	// Set up some default values..
	m_fGain = defaultGain;
	m_fDelay = defaultDelay;
	m_fDelayTime = defaultDelayTime;
	m_fPan = defaultPan;
    m_fBypass = defaultBypass;
    m_fMidSideParam= defaultMidSide;

	lastUIWidth = 400;
	lastUIHeight = 200;

	lastPosInfo.resetToDefault();
	delayPosition = 0;
}

JuceDemoPluginAudioProcessor::~JuceDemoPluginAudioProcessor()
{
}

//==============================================================================
int JuceDemoPluginAudioProcessor::getNumParameters()
{
	return totalNumParams;
}

float JuceDemoPluginAudioProcessor::getParameter(int index)
{
    // This method will be called by the host, probably on the audio thread, so
    // it's absolutely time-critical. Don't use critical sections or anything
    // UI-related, or anything at all that may block in any way!
    switch (index)
    {
        case bypassParam:
            return m_fBypass;
        case gainParam:
            return m_fGain;
        case delayParam:
            return m_fDelay;
        case delayTimeParam:
            return m_fDelayTime;
        case panParam:
            return m_fPan;
        case midSideParam:
            return m_fMidSideParam;
        default:
            return 0.0f;
    }
}

void JuceDemoPluginAudioProcessor::setParameter (int index, float newValue)
{
	// This method will be called by the host, probably on the audio thread, so
	// it's absolutely time-critical. Don't use critical sections or anything
	// UI-related, or anything at all that may block in any way!
	switch (index)
	{
        case bypassParam:
            m_fBypass   = newValue; 
            break;
        case gainParam:     
            m_fGain     = newValue;  
            break;
        case delayParam:    
            m_fDelay    = newValue;  
            break;
        case delayTimeParam:
            m_fDelayTime    = newValue;  
            break;
        case panParam:    
            m_fPan      = newValue;  
            break;
        case midSideParam:
            m_fMidSideParam = newValue;
            break;
        default:            
            break;
    }
}

float JuceDemoPluginAudioProcessor::getParameterDefaultValue (int index)
{
	switch (index)
	{
        case bypassParam: return defaultBypass;
        case gainParam:     return defaultGain;
        case delayParam:    return defaultDelay;
        case delayTimeParam:    return defaultDelayTime;
        case panParam:    return defaultPan;
        case midSideParam:    return defaultMidSide;
        default:            break;
	}

	return 0.0f;
}

const String JuceDemoPluginAudioProcessor::getParameterName(int index)
{
    switch (index)
    {
        case bypassParam:     return "bypass";
        case gainParam:     return "gain";
        case delayParam:    return "delay";
        case delayTimeParam:    return "delay time";
        case panParam:    return "pan";
        case midSideParam:    return "mid/side";
        default:            break;
    }

    return String::empty;
}

const String JuceDemoPluginAudioProcessor::getParameterText (int index)
{
	return String (getParameter (index), 2);
}

//==============================================================================
void JuceDemoPluginAudioProcessor::prepareToPlay (double sampleRate, int /*samplesPerBlock*/)
{
	// Use this method as the place to do any pre-playback
	// initialisation that you need..
	delayBuffer.clear();
}

void JuceDemoPluginAudioProcessor::releaseResources()
{
	// When playback stops, you can use this as an opportunity to free up any
	// spare memory, etc.
	//keyboardState.reset();
}

void JuceDemoPluginAudioProcessor::reset()
{
	// Use this method as the place to clear any delay lines, buffers, etc, as it
	// means there's been a break in the audio's continuity.
	delayBuffer.clear();
}


void JuceDemoPluginAudioProcessor::processBlock (AudioSampleBuffer& buffer, MidiBuffer& midiMessages)
{
    if (m_fBypass==1.0f || getNumInputChannels() < 2)
    {
        return;
    }

	const int numSamples = buffer.getNumSamples();
	
	int channel, dp = 0;

	// Go through the incoming data, and apply our gain to it...
    //for (channel = 0; channel < getNumInputChannels(); ++channel)
    //{
    //    buffer.applyGain(channel, 0, buffer.getNumSamples(), this->m_fGain);//apply gain parameter
    //}

	float lGain = 1;
	float rGain = 1;
	if (m_fPan < 0.5f){
		rGain = 1-  (0.5f- m_fPan)*2;
	}
	if (m_fPan > 0.5f){
		lGain =1- (m_fPan-0.5f)*2;
	}

    float* leftData = buffer.getWritePointer(0);
    float* rightData = buffer.getWritePointer(1);
    for (int i = 0; i < numSamples; ++i)
    {
        //float coef_S = m_fMidSideParam*0.5;

        float m = (1.0f - m_fMidSideParam)*(leftData[i] + rightData[i]) / 2;
        float s = ((rightData[i] - leftData[i]) / 2) * m_fMidSideParam;

        leftData[i] = (m - s)*lGain*m_fGain;
        rightData[i] = (m + s)*rGain*m_fGain;
    }
	//pan0 -> l1 r0
	//pan1 -> l0 r1
	// Apply our delay effect to the new output..
	
	//for (channel = 0; channel < getNumInputChannels(); ++channel)
	//{
	//	float* channelData = buffer.getWritePointer (channel);
	//	

	//	//delay
	//	float* delayData = delayBuffer.getWritePointer (juce::jmin (channel, delayBuffer.getNumChannels() - 1));
	//	dp = delayPosition;

	//	for (int i = 0; i < numSamples; ++i)
	//	{
	//		const float in = channelData[i];
	//		channelData[i] += delayData[dp];
	//		delayData[dp] = (delayData[dp] + in) * m_fDelay;
	//		if (++dp >= delayBuffer.getNumSamples())
	//			dp = 0;
	//	}
	//}

	//delayPosition = dp;

	// In case we have more outputs than inputs, we'll clear any output
	// channels that didn't contain input data, (because these aren't
	// guaranteed to be empty - they may contain garbage).
	for (int i = getNumInputChannels(); i < getNumOutputChannels(); ++i)
		buffer.clear (i, 0, buffer.getNumSamples());

	// ask the host for the current time so we can display it...
	AudioPlayHead::CurrentPositionInfo newTime;

	if (getPlayHead() != nullptr && getPlayHead()->getCurrentPosition (newTime))
	{
		// Successfully got the current time from the host..
		lastPosInfo = newTime;
	}
	else
	{
		// If the host fails to fill-in the current time, we'll just clear it to a default..
		lastPosInfo.resetToDefault();
	}
}

//==============================================================================
AudioProcessorEditor* JuceDemoPluginAudioProcessor::createEditor()
{
	return new JuceDemoPluginAudioProcessorEditor (this);
}

//==============================================================================
void JuceDemoPluginAudioProcessor::getStateInformation (MemoryBlock& destData)
{
	// You should use this method to store your parameters in the memory block.
	// Here's an example of how you can use XML to make it easy and more robust:

	// Create an outer XML element..
	XmlElement xml ("MYPLUGINSETTINGS");

	// add some attributes to it..
	xml.setAttribute ("uiWidth", lastUIWidth);
	xml.setAttribute ("uiHeight", lastUIHeight);
	xml.setAttribute ("gain", m_fGain);
	xml.setAttribute ("delay", m_fDelay);
	xml.setAttribute ("delayTime", m_fDelayTime);
	xml.setAttribute ("pan", m_fPan);

	// then use this helper function to stuff it into the binary blob and return it..
	copyXmlToBinary (xml, destData);
}

void JuceDemoPluginAudioProcessor::setStateInformation (const void* data, int sizeInBytes)
{
	// You should use this method to restore your parameters from this memory block,
	// whose contents will have been created by the getStateInformation() call.

	// This getXmlFromBinary() helper function retrieves our XML from the binary blob..
	ScopedPointer<XmlElement> xmlState (getXmlFromBinary (data, sizeInBytes));

	if (xmlState != nullptr)
	{
		// make sure that it's actually our type of XML object..
		if (xmlState->hasTagName ("MYPLUGINSETTINGS"))
		{
			// ok, now pull out our parameters..
			lastUIWidth  = xmlState->getIntAttribute ("uiWidth", lastUIWidth);
			lastUIHeight = xmlState->getIntAttribute ("uiHeight", lastUIHeight);

			m_fGain  = (float) xmlState->getDoubleAttribute ("gain", m_fGain);
			m_fDelay = (float) xmlState->getDoubleAttribute ("delay", m_fDelay);
			m_fDelayTime = (float) xmlState->getDoubleAttribute ("delayTime", m_fDelay);
			m_fPan = (float) xmlState->getDoubleAttribute ("pan", m_fPan);
		}
	}
}

const String JuceDemoPluginAudioProcessor::getInputChannelName (const int channelIndex) const
{
	return String (channelIndex + 1);
}

const String JuceDemoPluginAudioProcessor::getOutputChannelName (const int channelIndex) const
{
	return String (channelIndex + 1);
}

bool JuceDemoPluginAudioProcessor::isInputChannelStereoPair (int /*index*/) const
{
	return true;
}

bool JuceDemoPluginAudioProcessor::isOutputChannelStereoPair (int /*index*/) const
{
	return true;
}

bool JuceDemoPluginAudioProcessor::acceptsMidi() const
{
#if JucePlugin_WantsMidiInput
	return true;
#else
	return false;
#endif
}

bool JuceDemoPluginAudioProcessor::producesMidi() const
{
#if JucePlugin_ProducesMidiOutput
	return true;
#else
	return false;
#endif
}

bool JuceDemoPluginAudioProcessor::silenceInProducesSilenceOut() const
{
	return false;
}

double JuceDemoPluginAudioProcessor::getTailLengthSeconds() const
{
	return 0.0;
}

//==============================================================================
// This creates new instances of the plugin..
AudioProcessor* JUCE_CALLTYPE createPluginFilter()
{
	return new JuceDemoPluginAudioProcessor();
}
